####### FOR INVERTED LABELS ############
#### 1- LIVE, 0 - SPOOF
gpu: 0

show_imgs: False

loss_coef:  # coefficients for losses
  clf_loss: 5.0
  reg_loss: 5.0
  trip_loss: 1.0

lr: 0.001  # optimizer lr
milestones:  # MultiStepLR scheduler params
  - 4
  - 8
  - 12
  - 20
gamma: 0.3

image_size: 224  # size of input image
cue_log_every: 5000  # will log cues every cue_log_every batches. If 0, than won't log
#mean:
#  r: 100
#  g: 100
#  b: 100
#std:
#  r: 80
#  g: 80
#  b: 80

mean:
  r: 0
  g: 0
  b: 0
std:
  r: 1
  g: 1
  b: 1

#mean:
#  r: 0.485
#  g: 0.456
#  b: 0.406
#std:
#  r: 0.229
#  g: 0.224
#  b: 0.225

# uncomment this, to use online face cropping
# however it is not recommended
# you can only use cpu device as device for face-cropping nn
#face_detector:
#  image_size: 512
#  margin: 100
#  min_face_size: 100
#  thresholds: [0.6, 0.7, 0.7]
#  factor: 0.709
#  device: *device

train_df: "/root/datasets/meta-fas-experiment/baseline/train.csv"  # path to train csv file
val_df: "/root/datasets/meta-fas-experiment/baseline/val.csv"  # path to validation csv file
path_root: "/root/datasets/combined"  # prefix path to your images

batch_size: 32  # batch size for both validation and train dataloader
num_workers_train: 0  # param for training dataloader
num_workers_val: 0  # param for validation dataloader

default_root_dir: "/root/lgsc/logs/baseline"  # path to save pytorch_lightning logs
max_epochs: 30  # max number of epochs to train (if doesn't achieved early stopping)

use_balance_sampler: False  # You can try overcome class disbalance using balance sampler
use_weighted_sampler: True d # You can try overcome class disbalance using weighted sampler
use_focal_loss: False  # You can try use focal loss instead of cross-entropy loss

data:
  train:
    live: 28316
    fake: 46887
  val:
    live: 11918
    fake: 32609